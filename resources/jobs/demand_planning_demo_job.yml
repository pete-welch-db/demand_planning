resources:
  jobs:
    Demand_Planning_Demo_Job:
      name: "Demand Planning Demo Job"
      tags:
        RemoveAfter: "12/31/2026"
        owner: "pete.welch"
      queue:
        enabled: true
      tasks:
        - task_key: UC_Setup
          notebook_task:
            notebook_path: ${workspace.file_path}/notebooks/01_uc_setup
            base_parameters:
              catalog: "${var.catalog}"
              schema: "${var.schema}"
          new_cluster:
            spark_version: "15.4.x-scala2.12"
            node_type_id: "Standard_DS3_v2"
            num_workers: 1

        - task_key: Generate_Bronze
          depends_on:
            - task_key: UC_Setup
          notebook_task:
            notebook_path: ${workspace.file_path}/notebooks/02_generate_bronze
            base_parameters:
              catalog: "${var.catalog}"
              schema: "${var.schema}"
          new_cluster:
            spark_version: "15.4.x-scala2.12"
            node_type_id: "Standard_DS3_v2"
            num_workers: 2

        - task_key: DLT_Pipeline
          depends_on:
            - task_key: Generate_Bronze
          pipeline_task:
            pipeline_id: "${var.existing_dlt_pipeline_id}"
            full_refresh: false

        - task_key: Weekly_Forecast_ML
          depends_on:
            - task_key: DLT_Pipeline
          notebook_task:
            notebook_path: ${workspace.file_path}/notebooks/03_forecast_weekly_mlflow
            base_parameters:
              catalog: "${var.catalog}"
              schema: "${var.schema}"
          new_cluster:
            spark_version: "15.4.x-scala2.12"
            node_type_id: "Standard_DS3_v2"
            num_workers: 2

        # Needed for dashboards: creates `kpi_mape_weekly` and `demand_vs_forecast_weekly`
        - task_key: Post_Forecast_KPIs
          depends_on:
            - task_key: Weekly_Forecast_ML
          notebook_task:
            notebook_path: ${workspace.file_path}/notebooks/04_post_forecast_kpis.py
            base_parameters:
              catalog: "${var.catalog}"
              schema: "${var.schema}"
          new_cluster:
            spark_version: "15.4.x-scala2.12"
            node_type_id: "Standard_DS3_v2"
            num_workers: 1

        - task_key: ML_Late_Risk
          depends_on:
            - task_key: Post_Forecast_KPIs
          notebook_task:
            notebook_path: ${workspace.file_path}/notebooks/05_ml_late_risk
            base_parameters:
              catalog: "${var.catalog}"
              schema: "${var.schema}"
              model_name: "${var.late_risk_model_name}"
              train_lookback_days: "540"
              test_days: "90"
          new_cluster:
            spark_version: "15.4.x-scala2.12"
            node_type_id: "Standard_DS3_v2"
            num_workers: 2

        - task_key: Demand_Planner_Dashboard
          depends_on:
            - task_key: ML_Late_Risk
          notebook_task:
            notebook_path: ${workspace.file_path}/notebooks/90_dashboard_demand_planner
            base_parameters:
              catalog: "${var.catalog}"
              schema: "${var.schema}"
          new_cluster:
            spark_version: "15.4.x-scala2.12"
            node_type_id: "Standard_DS3_v2"
            num_workers: 1

        - task_key: Logistics_Service_Dashboard
          depends_on:
            - task_key: Demand_Planner_Dashboard
          notebook_task:
            notebook_path: ${workspace.file_path}/notebooks/91_dashboard_logistics_service
            base_parameters:
              catalog: "${var.catalog}"
              schema: "${var.schema}"
          new_cluster:
            spark_version: "15.4.x-scala2.12"
            node_type_id: "Standard_DS3_v2"
            num_workers: 1

        - task_key: Sustainability_Dashboard
          depends_on:
            - task_key: Logistics_Service_Dashboard
          notebook_task:
            notebook_path: ${workspace.file_path}/notebooks/92_dashboard_sustainability
            base_parameters:
              catalog: "${var.catalog}"
              schema: "${var.schema}"
          new_cluster:
            spark_version: "15.4.x-scala2.12"
            node_type_id: "Standard_DS3_v2"
            num_workers: 1

