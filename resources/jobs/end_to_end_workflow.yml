resources:
  jobs:
    demand_planning_end_to_end:
      name: "${var.demo_name}-end-to-end"
      tasks:
        # Ensure catalog/schema exist (best-effort)
        - task_key: uc_setup
          notebook_task:
            notebook_path: ${workspace.file_path}/notebooks/01_uc_setup
            base_parameters:
              catalog: "${var.catalog}"
              schema: "${var.schema}"
          new_cluster:
            spark_version: "15.4.x-scala2.12"
            node_type_id: "Standard_DS3_v2"
            num_workers: 1

        # Generate Bronze/raw synthetic data (single source of truth)
        - task_key: generate_bronze
          depends_on:
            - task_key: uc_setup
          notebook_task:
            notebook_path: ${workspace.file_path}/notebooks/02_generate_bronze
            base_parameters:
              catalog: "${var.catalog}"
              schema: "${var.schema}"
          new_cluster:
            spark_version: "15.4.x-scala2.12"
            node_type_id: "Standard_DS3_v2"
            num_workers: 2

        # Materialize Bronze→Silver→Gold via Lakeflow SDP/DLT
        - task_key: run_dlt_pipeline
          depends_on:
            - task_key: generate_bronze
          pipeline_task:
            pipeline_id: ${resources.pipelines.supply_chain_medallion.id}

        # Forecasting (writes demand_forecast tables used by KPIs/app)
        - task_key: forecasting_mlflow
          depends_on:
            - task_key: run_dlt_pipeline
          notebook_task:
            notebook_path: ${workspace.file_path}/notebooks/03_forecast_weekly_mlflow
            base_parameters:
              catalog: "${var.catalog}"
              schema: "${var.schema}"
          new_cluster:
            spark_version: "15.4.x-scala2.12"
            node_type_id: "Standard_DS3_v2"
            num_workers: 2

        # KPI views refresh (MAPE depends on demand_forecast)
        - task_key: kpis_refresh
          depends_on:
            - task_key: forecasting_mlflow
          notebook_task:
            notebook_path: ${workspace.file_path}/notebooks/04_post_forecast_kpis
            base_parameters:
              catalog: "${var.catalog}"
              schema: "${var.schema}"
          new_cluster:
            spark_version: "15.4.x-scala2.12"
            node_type_id: "Standard_DS3_v2"
            num_workers: 1

        # ML in the loop (late-risk): requires Silver tables from DLT
        - task_key: train_register_late_risk
          depends_on:
            - task_key: run_dlt_pipeline
          notebook_task:
            notebook_path: ${workspace.file_path}/notebooks/05_ml_late_risk
            base_parameters:
              catalog: "${var.catalog}"
              schema: "${var.schema}"
              model_name: "${var.late_risk_model_name}"
              train_lookback_days: "540"
              test_days: "90"
          new_cluster:
            spark_version: "15.4.x-scala2.12"
            node_type_id: "Standard_DS3_v2"
            num_workers: 2

